{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I4ch5VWAjFq",
        "outputId": "de22d925-defb-46dc-a774-602e20d7987d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 40 images belonging to 4 classes.\n",
            "Found 40 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 22s 22s/step - loss: 1.3805 - accuracy: 0.2250 - val_loss: 1.3252 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 18s 18s/step - loss: 1.3371 - accuracy: 0.6000 - val_loss: 1.2668 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 17s 17s/step - loss: 1.2752 - accuracy: 0.5750 - val_loss: 1.1448 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 1.1564 - accuracy: 0.7250 - val_loss: 0.9914 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 1.0062 - accuracy: 0.7000 - val_loss: 0.8229 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.9406 - accuracy: 0.7250 - val_loss: 0.6689 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.7202 - accuracy: 0.7250 - val_loss: 0.5545 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.4716 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.5283 - accuracy: 0.7250 - val_loss: 0.4132 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.4336 - accuracy: 0.7250 - val_loss: 0.3668 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 17s 17s/step - loss: 0.4520 - accuracy: 0.7000 - val_loss: 0.3417 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.4920 - accuracy: 0.7250 - val_loss: 0.3677 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 24s 24s/step - loss: 0.3707 - accuracy: 0.8250 - val_loss: 0.3271 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 21s 21s/step - loss: 0.3748 - accuracy: 0.8250 - val_loss: 0.3493 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.4167 - accuracy: 0.7750 - val_loss: 0.3478 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 18s 18s/step - loss: 0.4119 - accuracy: 0.8000 - val_loss: 0.3399 - val_accuracy: 0.7500 - lr: 2.0000e-04\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3271 - accuracy: 0.7500\n",
            "Test Accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Define dataset directories\n",
        "dataset_dir = pathlib.Path(\"/content/drive/MyDrive/weatherimages\")\n",
        "\n",
        "train_dir = dataset_dir / \"train\"\n",
        "test_dir = dataset_dir / \"test\"\n",
        "\n",
        "# Create necessary directories for the dataset\n",
        "classes = ['sunny', 'rainy', 'cloudy', 'snowy']\n",
        "\n",
        "# Create directories if they don't exist\n",
        "for split in [train_dir, test_dir]:\n",
        "    for cls in classes:\n",
        "        os.makedirs(split / cls, exist_ok=True)\n",
        "\n",
        "# Function to create a sample image\n",
        "def create_image(save_path, color):\n",
        "    img = Image.new('RGB', (400, 400), color=color)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.text((200, 200), color, fill='black')\n",
        "    img.save(save_path)\n",
        "\n",
        "# Generate images for each class\n",
        "colors = {'sunny': 'yellow', 'rainy': 'blue', 'cloudy': 'gray', 'snowy': 'white'}\n",
        "\n",
        "for cls, color in colors.items():\n",
        "    for i in range(10):\n",
        "        create_image(train_dir / cls / f'{cls}_{i}.jpg', color)\n",
        "        create_image(test_dir / cls / f'{cls}_{i}.jpg', color)\n",
        "\n",
        "# Define image size and batch size\n",
        "image_size = (400, 400)\n",
        "batch_size = 50\n",
        "\n",
        "# Data augmentation and normalization\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1.0/255\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Define model architecture\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(400, 400, 3)),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(3),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(3),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(2),\n",
        "    layers.Conv2D(128, 3, activation='relu'),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),  # Added dropout for regularization\n",
        "    layers.Dense(len(classes), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks for early stopping, learning rate scheduling, and model checkpointing\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=2),\n",
        "    keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=test_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    }
  ]
}